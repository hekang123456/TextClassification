{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_proc_hk import get_data\n",
    "from data.data_proc_hk import get_stop_words\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.externals import joblib\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数\n",
    "data_num = 10000 # 用于训练的数据量\n",
    "stop_words = get_stop_words()\n",
    "\n",
    "@nb.jit(forceobj=True, cache=True)\n",
    "def data_proc():\n",
    "  all_data = get_data()\n",
    "  tmp = []\n",
    "  for key in all_data:\n",
    "    val = all_data[key]\n",
    "    tmp .append(val)\n",
    "  all_data = tmp\n",
    "\n",
    "  texts = [item[2]+item[3] for item in all_data]\n",
    "  labels = [item[1] for item in all_data]\n",
    "  return np.array(texts), np.array(labels)\n",
    "\n",
    "texts, labels = data_proc()\n",
    "texts = texts[:data_num]\n",
    "labels = labels[:data_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTfIdf(all_texts):\n",
    "  # 一行表示一个文本， 分词之间按照空格隔开。\n",
    "  result = []\n",
    "  for line in all_texts:\n",
    "    tmp = list(jieba.cut(line.strip()))\n",
    "    tmp = [it for it in tmp if it not in stop_words]\n",
    "    tmp = \" \".join(tmp)\n",
    "    result.append(tmp)\n",
    "  \n",
    "  # 统计词频矩阵, 得到的内容 ： (句子id,  单词在词表中的id)  单词出现的次数\n",
    "  freWord = CountVectorizer()\n",
    "  tf = freWord.fit_transform(result)\n",
    "  # 统计每个词的 tf-idf 值， 得到的内容： (句子id, 单词在词表中的id) 对应这个单词的 tf-idf 值\n",
    "  tfidftrans = TfidfTransformer()\n",
    "  tfidf = tfidftrans.fit_transform(tf)\n",
    "\n",
    "  return tfidf\n",
    "\n",
    "allX = getTfIdf(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(allX, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingClassifier(n_estimators=3000, max_depth=2, min_samples_split=2, learning_rate=0.1)\n",
    "gbr.fit(x_train, y_train.ravel())\n",
    "joblib.dump(gbr, 'train_model_result4.m')   # 保存模型\n",
    "\n",
    "y_gbr = gbr.predict(x_train)\n",
    "y_gbr1 = gbr.predict(x_test)\n",
    "acc_train = gbr.score(x_train, y_train)\n",
    "acc_test = gbr.score(x_test, y_test)\n",
    "print(acc_train)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(gbr.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
